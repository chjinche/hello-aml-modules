{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Training Pipeline\n",
    "\n",
    "In this sample, image preprocessing is on cpu nodes while training on distributed gpu nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace and compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure workspace information here.\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "# forced_interactive_auth = InteractiveLoginAuthentication(tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\", force=True)\n",
    "\n",
    "ws = Workspace.get(\n",
    "    name='gjd-test',\n",
    "    subscription_id='f92fab0a-38b9-44ed-b800-2ed55fa1b9d9',\n",
    "    resource_group='Groot-Shared'\n",
    "    # auth=forced_interactive_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "This smaller imagenet dataset is a subset of the official one.\n",
    "- training dataset contains 1.2m images (1000 categories * 1200 images per category)\n",
    "- validation dataset contains 50k images (1000 categories * 50 images per category)\n",
    "\n",
    "Need to use zip file here to avoid perf issue of mounting file dataset with many subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "train_image_dataset = Dataset.get_by_name(ws, name='imagenet_train_dataset')\n",
    "val_image_dataset = Dataset.get_by_name(ws, name='imagenet_valid_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.component import Component\n",
    "\n",
    "# load built-in components\n",
    "convert_func, init_transform_func, apply_transform_func = Component.batch_load(ws, selectors=['azureml://Convert to Image Directory', 'azureml://Init Image Transformation', 'azureml://Apply Image Transformation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_module = Component.from_yaml(ws, yaml_file='modules/ConvNets/entry.spec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "# define pipeline\n",
    "from azure.ml.component import dsl\n",
    "\n",
    "compute_target = \"eus-p40-5-gjd\"\n",
    "datastore_name = 'chjinche_adls_gen1'\n",
    "\n",
    "@dsl.pipeline(name='image classification', description='image classification', default_compute_target=compute_target,\n",
    "default_datastore=datastore_name)\n",
    "def generated_pipeline():\n",
    "    convert_train = convert_func(\n",
    "        input_dataset=train_image_dataset\n",
    "    )\n",
    "    \n",
    "    convert_val = convert_func(\n",
    "        input_dataset=val_image_dataset\n",
    "    )\n",
    "    \n",
    "    init_trans = init_transform_func(\n",
    "        resize='False',\n",
    "        size=256,\n",
    "        center_crop='False',\n",
    "        crop_size=224,\n",
    "        pad='False',\n",
    "        padding=0,\n",
    "        color_jitter='False',\n",
    "        grayscale='False',\n",
    "        random_resized_crop='False',\n",
    "        random_resized_crop_size=256,\n",
    "        random_crop='False',\n",
    "        random_crop_size=224,\n",
    "        random_horizontal_flip='True',\n",
    "        random_vertical_flip='False',\n",
    "        random_rotation='False',\n",
    "        random_rotation_degrees=0,\n",
    "        random_affine='False',\n",
    "        random_affine_degrees=0,\n",
    "        random_grayscale='False',\n",
    "        random_perspective='False'\n",
    "    )\n",
    "    \n",
    "    apply_trans_on_train = apply_transform_func(\n",
    "        mode='For training',\n",
    "        input_image_transformation=init_trans.outputs.output_image_transformation,\n",
    "        input_image_directory=convert_train.outputs.output_image_directory\n",
    "    )\n",
    "    \n",
    "    apply_trans_on_val = apply_transform_func(\n",
    "        mode='For inference',\n",
    "        input_image_transformation=init_trans.outputs.output_image_transformation,\n",
    "        input_image_directory=convert_val.outputs.output_image_directory\n",
    "    )\n",
    "    \n",
    "    train = train_module(\n",
    "        train_data=apply_trans_on_train.outputs.output_image_directory,\n",
    "        valid_data=apply_trans_on_val.outputs.output_image_directory,\n",
    "        data_backend='pytorch',\n",
    "        pretrained_weights=None,\n",
    "        epochs=2,\n",
    "        seed=123,\n",
    "        batch_size=16,\n",
    "        print_freq=100,\n",
    "        # lr=4.096,\n",
    "        # optimizer_batch_size=4096,\n",
    "        save_checkpoint_epochs=1\n",
    "    )\n",
    "    # perform distributed training with 4 nodes.\n",
    "    # note: process_count_per_node should be 1 because this module will launch distributed processes based on node device count.\n",
    "    train.runsettings.configure(target=compute_target, node_count=2, process_count_per_node=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "pipeline = generated_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validate pipeline and visualize the graph\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.submit(experiment_name='test-gen1-itp-image-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('py37')",
   "language": "python",
   "name": "python37764bitpy370158f395e7c84e8c95aa9430462f7981"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}